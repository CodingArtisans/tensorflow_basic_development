{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tensorboard.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/houyingshi/tensorflow_basic_development/blob/master/tensorboard.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l6vaQ5-PwFXT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "@author: Yingshi Hou\n",
        "\"\"\"\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plotdata = {\"batchsize\": [], \"loss\": []}\n",
        "\n",
        "\n",
        "def moving_average(a, w=10):\n",
        "    if len(a) < w:\n",
        "        return a[:]\n",
        "    return [val if idx < w else sum(a[(idx - w):idx]) / w for idx, val in enumerate(a)]\n",
        "\n",
        "\n",
        "# 生成模拟数据\n",
        "train_X = np.linspace(-1, 1, 100)\n",
        "train_Y = 2 * train_X + np.random.randn(*train_X.shape) * 0.3  # y=2x，但是加入了噪声\n",
        "# 显示模拟数据点\n",
        "plt.plot(train_X, train_Y, 'ro', label='Original data')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# 创建模型\n",
        "# 占位符\n",
        "X = tf.placeholder(tf.float32)\n",
        "Y = tf.placeholder(tf.float32)\n",
        "# 模型参数\n",
        "W = tf.Variable(tf.random_normal([1]), name=\"weight\")\n",
        "b = tf.Variable(tf.zeros([1]), name=\"bias\")\n",
        "\n",
        "# 前向结构\n",
        "z = tf.multiply(X, W) + b\n",
        "\n",
        "tf.summary.histogram('z', z)\n",
        "\n",
        "# 反向优化\n",
        "cost = tf.reduce_mean(tf.square(Y - z))\n",
        "\n",
        "tf.summary.scalar('loss_function', cost)\n",
        "\n",
        "learning_rate = 0.01\n",
        "optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)  # Gradient descent\n",
        "\n",
        "# 初始化变量\n",
        "init = tf.global_variables_initializer()\n",
        "# 训练参数\n",
        "training_epochs = 20\n",
        "display_step = 2\n",
        "\n",
        "# 启动session\n",
        "with tf.Session() as sess:\n",
        "    sess.run(init)\n",
        "\n",
        "    merged_summary_op = tf.summary.merge_all()\n",
        "    summary_writer = tf.summary.FileWriter('tensorborad/liner_regression', sess.graph)\n",
        "    # Fit all training data\n",
        "    for epoch in range(training_epochs):\n",
        "        for (x, y) in zip(train_X, train_Y):\n",
        "            sess.run(optimizer, feed_dict={X: x, Y: y})\n",
        "\n",
        "        summary_str = sess.run(merged_summary_op, feed_dict={X:x, Y:y})\n",
        "        summary_writer.add_summary(summary_str, epoch)\n",
        "        # 显示训练中的详细信息\n",
        "        if epoch % display_step == 0:\n",
        "            loss = sess.run(cost, feed_dict={X: train_X, Y: train_Y})\n",
        "            print(\"Epoch:\", epoch + 1, \"cost=\", loss, \"W=\", sess.run(W), \"b=\", sess.run(b))\n",
        "            if not (loss == \"NA\"):\n",
        "                plotdata[\"batchsize\"].append(epoch)\n",
        "                plotdata[\"loss\"].append(loss)\n",
        "\n",
        "    print(\" Finished!\")\n",
        "    print(\"cost=\", sess.run(cost, feed_dict={X: train_X, Y: train_Y}), \"W=\", sess.run(W), \"b=\", sess.run(b))\n",
        "    # print (\"cost:\",cost.eval({X: train_X, Y: train_Y}))\n",
        "\n",
        "    # 图形显示\n",
        "    plt.plot(train_X, train_Y, 'ro', label='Original data')\n",
        "    plt.plot(train_X, sess.run(W) * train_X + sess.run(b), label='Fitted line')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "    plotdata[\"avgloss\"] = moving_average(plotdata[\"loss\"])\n",
        "    plt.figure(1)\n",
        "    plt.subplot(211)\n",
        "    plt.plot(plotdata[\"batchsize\"], plotdata[\"avgloss\"], 'b--')\n",
        "    plt.xlabel('Minibatch number')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.title('Minibatch run vs. Training loss')\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "    print(\"x=0.2，z=\", sess.run(z, feed_dict={X: 0.2}))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}